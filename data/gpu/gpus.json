[
  {
    "name": "GeForce 256 SDR",
    "year": 1999,
    "manufacturer": "NVIDIA",
    "series": "GeForce",
    "architecture": "NV10",
    "process_nm": 220,
    "transistors_millions": 23,
    "die_size_mm2": 139,
    "cuda_cores": null,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 120,
    "boost_clock_mhz": 120,
    "vram_mb": 32,
    "memory_type": "SDR",
    "memory_bus_width": 128,
    "memory_bandwidth_gbps": 2.9,
    "memory_clock_mhz": 166,
    "tflops_fp32": 0.48,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 30,
    "power_connectors": "None",
    "launch_price_usd": 299,
    "directx_version": "7.0",
    "opengl_version": "1.2",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2048x1536",
    "release_date": "1999-10",
    "notes": "First GPU with hardware T&L (Transform & Lighting) - coined the term 'GPU'. Revolutionary for 3D graphics acceleration."
  },
  {
    "name": "Radeon 7500",
    "year": 2001,
    "manufacturer": "AMD",
    "series": "Radeon",
    "architecture": "R200",
    "process_nm": 150,
    "transistors_millions": 30,
    "die_size_mm2": 81,
    "cuda_cores": null,
    "stream_processors": 64,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 290,
    "boost_clock_mhz": 290,
    "vram_mb": 64,
    "memory_type": "DDR",
    "memory_bus_width": 128,
    "memory_bandwidth_gbps": 7.4,
    "memory_clock_mhz": 230,
    "tflops_fp32": 1.2,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 25,
    "power_connectors": "None",
    "launch_price_usd": 199,
    "directx_version": "8.1",
    "opengl_version": "1.3",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2048x1536",
    "release_date": "2001-02",
    "notes": "Affordable mainstream GPU with dual display support and DirectX 8.1 compatibility."
  },
  {
    "name": "GeForce 6800 Ultra",
    "year": 2004,
    "manufacturer": "NVIDIA",
    "series": "GeForce 6",
    "architecture": "NV40",
    "process_nm": 130,
    "transistors_millions": 222,
    "die_size_mm2": 287,
    "cuda_cores": null,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 400,
    "boost_clock_mhz": 400,
    "vram_mb": 256,
    "memory_type": "GDDR3",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 35.2,
    "memory_clock_mhz": 550,
    "tflops_fp32": 5.6,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 110,
    "power_connectors": "6-pin",
    "launch_price_usd": 499,
    "directx_version": "9.0c",
    "opengl_version": "2.0",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2560x1600",
    "release_date": "2004-04",
    "notes": "First PCI Express GPU with Shader Model 3.0 support. Set new standards for graphics performance."
  },
  {
    "name": "Radeon X1900 XTX",
    "year": 2006,
    "manufacturer": "AMD",
    "series": "Radeon X1000",
    "architecture": "R580",
    "process_nm": 90,
    "transistors_millions": 384,
    "die_size_mm2": 352,
    "cuda_cores": null,
    "stream_processors": 384,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 650,
    "boost_clock_mhz": 650,
    "vram_mb": 512,
    "memory_type": "GDDR3",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 76.8,
    "memory_clock_mhz": 750,
    "tflops_fp32": 8.0,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 160,
    "power_connectors": "6-pin + 6-pin",
    "launch_price_usd": 649,
    "directx_version": "9.0c",
    "opengl_version": "2.0",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2560x1600",
    "release_date": "2006-01",
    "notes": "First consumer GPU with 512MB VRAM. Featured ultra-threaded shader architecture."
  },
  {
    "name": "GeForce 8800 GTX",
    "year": 2006,
    "manufacturer": "NVIDIA",
    "series": "GeForce 8",
    "architecture": "Tesla (G80)",
    "process_nm": 90,
    "transistors_millions": 681,
    "die_size_mm2": 484,
    "cuda_cores": 128,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 575,
    "boost_clock_mhz": 575,
    "vram_mb": 768,
    "memory_type": "GDDR3",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 86.4,
    "memory_clock_mhz": 900,
    "tflops_fp32": 13.8,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 155,
    "power_connectors": "6-pin",
    "launch_price_usd": 599,
    "directx_version": "10.0",
    "opengl_version": "2.1",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2560x1600",
    "release_date": "2006-11",
    "notes": "Revolutionary unified shader architecture. First GPU to introduce CUDA for general-purpose computing."
  },
  {
    "name": "Radeon HD 4870",
    "year": 2008,
    "manufacturer": "AMD",
    "series": "Radeon HD 4000",
    "architecture": "TeraScale (RV770)",
    "process_nm": 55,
    "transistors_millions": 956,
    "die_size_mm2": 256,
    "cuda_cores": null,
    "stream_processors": 800,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 750,
    "boost_clock_mhz": 750,
    "vram_mb": 512,
    "memory_type": "GDDR5",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 115.2,
    "memory_clock_mhz": 900,
    "tflops_fp32": 1.2,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 160,
    "power_connectors": "6-pin + 6-pin",
    "launch_price_usd": 299,
    "directx_version": "10.1",
    "opengl_version": "3.2",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2560x1600",
    "release_date": "2008-06",
    "notes": "First consumer GPU with GDDR5 memory, offering significantly higher bandwidth than GDDR3."
  },
  {
    "name": "GeForce GTX 480",
    "year": 2010,
    "manufacturer": "NVIDIA",
    "series": "GeForce GTX 400",
    "architecture": "Fermi (GF100)",
    "process_nm": 40,
    "transistors_millions": 3000,
    "die_size_mm2": 529,
    "cuda_cores": 480,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 700,
    "boost_clock_mhz": 700,
    "vram_mb": 1536,
    "memory_type": "GDDR5",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 177.4,
    "memory_clock_mhz": 924,
    "tflops_fp32": 1.35,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 250,
    "power_connectors": "6-pin + 8-pin",
    "launch_price_usd": 499,
    "directx_version": "11.0",
    "opengl_version": "4.1",
    "vulkan_support": false,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 2,
    "max_resolution": "2560x1600",
    "release_date": "2010-03",
    "notes": "First Fermi architecture GPU with enhanced double precision performance. Important for scientific computing."
  },
  {
    "name": "Radeon HD 7970",
    "year": 2011,
    "manufacturer": "AMD",
    "series": "Radeon HD 7000",
    "architecture": "GCN 1.0 (Tahiti)",
    "process_nm": 28,
    "transistors_millions": 4313,
    "die_size_mm2": 365,
    "cuda_cores": null,
    "stream_processors": 2048,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 925,
    "boost_clock_mhz": 925,
    "vram_mb": 3072,
    "memory_type": "GDDR5",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 264,
    "memory_clock_mhz": 1375,
    "tflops_fp32": 3.79,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 250,
    "power_connectors": "6-pin + 8-pin",
    "launch_price_usd": 549,
    "directx_version": "11.1",
    "opengl_version": "4.2",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 6,
    "max_resolution": "4096x2160",
    "release_date": "2011-12",
    "notes": "First 28nm GPU and debut of GCN (Graphics Core Next) architecture. Set new standards for compute performance."
  },
  {
    "name": "GeForce GTX 680",
    "year": 2012,
    "manufacturer": "NVIDIA",
    "series": "GeForce GTX 600",
    "architecture": "Kepler (GK104)",
    "process_nm": 28,
    "transistors_millions": 3540,
    "die_size_mm2": 294,
    "cuda_cores": 1536,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1006,
    "boost_clock_mhz": 1058,
    "vram_mb": 2048,
    "memory_type": "GDDR5",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 192.2,
    "memory_clock_mhz": 1502,
    "tflops_fp32": 3.25,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 195,
    "power_connectors": "6-pin + 6-pin",
    "launch_price_usd": 499,
    "directx_version": "11.0",
    "opengl_version": "4.3",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "4096x2160",
    "release_date": "2012-03",
    "notes": "Kepler architecture with GPU Boost technology for dynamic clock adjustment based on thermals."
  },
  {
    "name": "GeForce GTX 780 Ti",
    "year": 2013,
    "manufacturer": "NVIDIA",
    "series": "GeForce GTX 700",
    "architecture": "Kepler (GK110)",
    "process_nm": 28,
    "transistors_millions": 7080,
    "die_size_mm2": 561,
    "cuda_cores": 2880,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 875,
    "boost_clock_mhz": 928,
    "vram_mb": 3072,
    "memory_type": "GDDR5",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 336,
    "memory_clock_mhz": 1750,
    "tflops_fp32": 5.04,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 250,
    "power_connectors": "6-pin + 8-pin",
    "launch_price_usd": 699,
    "directx_version": "11.0",
    "opengl_version": "4.4",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "4096x2160",
    "release_date": "2013-11",
    "notes": "Full GK110 chip implementation. Fastest single-GPU consumer card of 2013."
  },
  {
    "name": "Radeon R9 290X",
    "year": 2013,
    "manufacturer": "AMD",
    "series": "Radeon R9 200",
    "architecture": "GCN 2.0 (Hawaii)",
    "process_nm": 28,
    "transistors_millions": 6200,
    "die_size_mm2": 438,
    "cuda_cores": null,
    "stream_processors": 2816,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1000,
    "boost_clock_mhz": 1000,
    "vram_mb": 4096,
    "memory_type": "GDDR5",
    "memory_bus_width": 512,
    "memory_bandwidth_gbps": 320,
    "memory_clock_mhz": 1250,
    "tflops_fp32": 5.63,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 290,
    "power_connectors": "6-pin + 8-pin",
    "launch_price_usd": 549,
    "directx_version": "11.2",
    "opengl_version": "4.4",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 6,
    "max_resolution": "4096x2160",
    "release_date": "2013-10",
    "notes": "First consumer GPU with 512-bit memory bus and 4GB VRAM as standard."
  },
  {
    "name": "GeForce GTX 980 Ti",
    "year": 2015,
    "manufacturer": "NVIDIA",
    "series": "GeForce GTX 900",
    "architecture": "Maxwell (GM200)",
    "process_nm": 28,
    "transistors_millions": 8000,
    "die_size_mm2": 601,
    "cuda_cores": 2816,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1000,
    "boost_clock_mhz": 1075,
    "vram_mb": 6144,
    "memory_type": "GDDR5",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 336.5,
    "memory_clock_mhz": 1753,
    "tflops_fp32": 5.63,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 250,
    "power_connectors": "6-pin + 8-pin",
    "launch_price_usd": 649,
    "directx_version": "12.0",
    "opengl_version": "4.5",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "5120x2880",
    "release_date": "2015-06",
    "notes": "Peak of Maxwell architecture with excellent power efficiency. Legendary performance-per-watt ratio."
  },
  {
    "name": "Radeon R9 Fury X",
    "year": 2015,
    "manufacturer": "AMD",
    "series": "Radeon R9 Fury",
    "architecture": "GCN 3.0 (Fiji)",
    "process_nm": 28,
    "transistors_millions": 8900,
    "die_size_mm2": 596,
    "cuda_cores": null,
    "stream_processors": 4096,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1050,
    "boost_clock_mhz": 1050,
    "vram_mb": 4096,
    "memory_type": "HBM",
    "memory_bus_width": 4096,
    "memory_bandwidth_gbps": 512,
    "memory_clock_mhz": 500,
    "tflops_fp32": 8.6,
    "tflops_fp16": 0.0,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 275,
    "power_connectors": "8-pin + 8-pin",
    "launch_price_usd": 649,
    "directx_version": "12.0",
    "opengl_version": "4.5",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 6,
    "max_resolution": "5120x2880",
    "release_date": "2015-06",
    "notes": "First consumer GPU with HBM (High Bandwidth Memory), pioneering stacked memory technology."
  },
  {
    "name": "GeForce GTX 1080",
    "year": 2016,
    "manufacturer": "NVIDIA",
    "series": "GeForce GTX 10",
    "architecture": "Pascal (GP104)",
    "process_nm": 16,
    "transistors_millions": 7200,
    "die_size_mm2": 314,
    "cuda_cores": 2560,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1607,
    "boost_clock_mhz": 1733,
    "vram_mb": 8192,
    "memory_type": "GDDR5X",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 320,
    "memory_clock_mhz": 1251,
    "tflops_fp32": 8.87,
    "tflops_fp16": 0.28,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 180,
    "power_connectors": "8-pin",
    "launch_price_usd": 599,
    "directx_version": "12.1",
    "opengl_version": "4.5",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2016-05",
    "notes": "First 16nm FinFET GPU. Introduced GDDR5X memory for higher bandwidth."
  },
  {
    "name": "GeForce GTX 1080 Ti",
    "year": 2017,
    "manufacturer": "NVIDIA",
    "series": "GeForce GTX 10",
    "architecture": "Pascal (GP102)",
    "process_nm": 16,
    "transistors_millions": 12000,
    "die_size_mm2": 471,
    "cuda_cores": 3584,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1480,
    "boost_clock_mhz": 1582,
    "vram_mb": 11264,
    "memory_type": "GDDR5X",
    "memory_bus_width": 352,
    "memory_bandwidth_gbps": 484,
    "memory_clock_mhz": 1376,
    "tflops_fp32": 11.34,
    "tflops_fp16": 0.35,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 250,
    "power_connectors": "6-pin + 8-pin",
    "launch_price_usd": 699,
    "directx_version": "12.1",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2017-03",
    "notes": "Full GP102 chip with 11GB VRAM. Legendary value proposition and longevity."
  },
  {
    "name": "Radeon RX Vega 64",
    "year": 2017,
    "manufacturer": "AMD",
    "series": "Radeon RX Vega",
    "architecture": "GCN 5.0 (Vega 10)",
    "process_nm": 14,
    "transistors_millions": 12500,
    "die_size_mm2": 495,
    "cuda_cores": null,
    "stream_processors": 4096,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1247,
    "boost_clock_mhz": 1546,
    "vram_mb": 8192,
    "memory_type": "HBM2",
    "memory_bus_width": 2048,
    "memory_bandwidth_gbps": 483.8,
    "memory_clock_mhz": 945,
    "tflops_fp32": 12.66,
    "tflops_fp16": 25.3,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 295,
    "power_connectors": "8-pin + 8-pin",
    "launch_price_usd": 499,
    "directx_version": "12.1",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 6,
    "max_resolution": "7680x4320",
    "release_date": "2017-08",
    "notes": "HBM2 memory with strong compute performance. Popular for early cryptocurrency mining."
  },
  {
    "name": "GeForce RTX 2080 Ti",
    "year": 2018,
    "manufacturer": "NVIDIA",
    "series": "GeForce RTX 20",
    "architecture": "Turing (TU102)",
    "process_nm": 12,
    "transistors_millions": 18600,
    "die_size_mm2": 754,
    "cuda_cores": 4352,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 544,
    "rt_cores": 68,
    "base_clock_mhz": 1350,
    "boost_clock_mhz": 1545,
    "vram_mb": 11264,
    "memory_type": "GDDR6",
    "memory_bus_width": 352,
    "memory_bandwidth_gbps": 616,
    "memory_clock_mhz": 1750,
    "tflops_fp32": 13.45,
    "tflops_fp16": 26.9,
    "tflops_int8": 107.6,
    "ray_tracing_tflops": 10.0,
    "tdp_watts": 260,
    "power_connectors": "8-pin + 8-pin",
    "launch_price_usd": 999,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2018-09",
    "notes": "Revolutionary first consumer GPU with dedicated RT cores and Tensor cores. Introduced DLSS 1.0 and real-time ray tracing."
  },
  {
    "name": "Radeon RX 5700 XT",
    "year": 2019,
    "manufacturer": "AMD",
    "series": "Radeon RX 5000",
    "architecture": "RDNA 1.0 (Navi 10)",
    "process_nm": 7,
    "transistors_millions": 10300,
    "die_size_mm2": 251,
    "cuda_cores": null,
    "stream_processors": 2560,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": null,
    "base_clock_mhz": 1605,
    "boost_clock_mhz": 1905,
    "vram_mb": 8192,
    "memory_type": "GDDR6",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 448,
    "memory_clock_mhz": 1750,
    "tflops_fp32": 9.75,
    "tflops_fp16": 19.5,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": null,
    "tdp_watts": 225,
    "power_connectors": "8-pin + 6-pin",
    "launch_price_usd": 399,
    "directx_version": "12.0",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2019-07",
    "notes": "First RDNA architecture on 7nm process. Significant efficiency improvement over GCN."
  },
  {
    "name": "NVIDIA A100 40GB PCIe",
    "year": 2020,
    "manufacturer": "NVIDIA",
    "series": "A100",
    "architecture": "Ampere",
    "process_nm": 7,
    "transistors_millions": 54000,
    "die_size_mm2": 826,
    "cuda_cores": 6912,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 432,
    "rt_cores": null,
    "base_clock_mhz": 765,
    "boost_clock_mhz": 1410,
    "vram_mb": 40960,
    "memory_type": "HBM2",
    "memory_bus_width": 5120,
    "memory_bandwidth_gbps": 1555,
    "memory_clock_mhz": 1215,
    "tflops_fp32": 19.5,
    "tflops_fp16": 312,
    "tflops_int8": 624,
    "ray_tracing_tflops": null,
    "tdp_watts": 250,
    "power_connectors": "PCIe 8-pin",
    "launch_price_usd": 10000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2020-05",
    "notes": "Data center GPU with HBM2 memory, designed for AI training and HPC workloads. Supports Multi-Instance GPU (MIG) technology with up to 7 instances. Third-generation Tensor Cores with TF32 precision."
  },
  {
    "name": "NVIDIA A100 80GB SXM",
    "year": 2020,
    "manufacturer": "NVIDIA",
    "series": "A100",
    "architecture": "Ampere",
    "process_nm": 7,
    "transistors_millions": 54000,
    "die_size_mm2": 826,
    "cuda_cores": 6912,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 432,
    "rt_cores": null,
    "base_clock_mhz": 765,
    "boost_clock_mhz": 1410,
    "vram_mb": 81920,
    "memory_type": "HBM2e",
    "memory_bus_width": 5120,
    "memory_bandwidth_gbps": 2039,
    "memory_clock_mhz": 1593,
    "tflops_fp32": 19.5,
    "tflops_fp16": 312,
    "tflops_int8": 624,
    "ray_tracing_tflops": null,
    "tdp_watts": 400,
    "power_connectors": "SXM4",
    "launch_price_usd": 12000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2020-11",
    "notes": "High-end data center GPU with 80GB HBM2e memory and 2TB/s bandwidth. Optimized for large-scale AI training. NVLink 3.0 support provides 600GB/s interconnect bandwidth for multi-GPU scaling."
  },
  {
    "name": "GeForce RTX 3080",
    "year": 2020,
    "manufacturer": "NVIDIA",
    "series": "GeForce RTX 30",
    "architecture": "Ampere (GA102)",
    "process_nm": 8,
    "transistors_millions": 28000,
    "die_size_mm2": 628,
    "cuda_cores": 8704,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 272,
    "rt_cores": 68,
    "base_clock_mhz": 1440,
    "boost_clock_mhz": 1710,
    "vram_mb": 10240,
    "memory_type": "GDDR6X",
    "memory_bus_width": 320,
    "memory_bandwidth_gbps": 760,
    "memory_clock_mhz": 1188,
    "tflops_fp32": 29.77,
    "tflops_fp16": 59.5,
    "tflops_int8": 238,
    "ray_tracing_tflops": 58.0,
    "tdp_watts": 320,
    "power_connectors": "12-pin",
    "launch_price_usd": 699,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2020-09",
    "notes": "Second-gen RT cores and Tensor cores with DLSS 2.0. Excellent value for 4K gaming and entry-level AI development."
  },
  {
    "name": "NVIDIA GeForce RTX 3090",
    "year": 2020,
    "manufacturer": "NVIDIA",
    "series": "RTX 30",
    "architecture": "Ampere",
    "process_nm": 8,
    "transistors_millions": 28300,
    "die_size_mm2": 628,
    "cuda_cores": 10496,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 328,
    "rt_cores": 82,
    "base_clock_mhz": 1395,
    "boost_clock_mhz": 1695,
    "vram_mb": 24576,
    "memory_type": "GDDR6X",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 936.2,
    "memory_clock_mhz": 19500,
    "tflops_fp32": 35.58,
    "tflops_fp16": 285,
    "tflops_int8": 285,
    "ray_tracing_tflops": 69,
    "tdp_watts": 350,
    "power_connectors": "1x 12-pin or 2x 8-pin",
    "launch_price_usd": 1499,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2020-09",
    "notes": "Consumer flagship with 24GB GDDR6X. Extremely popular for AI research and smaller LLM training due to large VRAM. Supports NVLink for 2-way configurations."
  },
  {
    "name": "Radeon RX 6800 XT",
    "year": 2020,
    "manufacturer": "AMD",
    "series": "Radeon RX 6000",
    "architecture": "RDNA 2.0 (Navi 21)",
    "process_nm": 7,
    "transistors_millions": 26800,
    "die_size_mm2": 519,
    "cuda_cores": null,
    "stream_processors": 4608,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": 72,
    "base_clock_mhz": 1825,
    "boost_clock_mhz": 2250,
    "vram_mb": 16384,
    "memory_type": "GDDR6",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 512,
    "memory_clock_mhz": 2000,
    "tflops_fp32": 20.74,
    "tflops_fp16": 41.47,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": 41.0,
    "tdp_watts": 300,
    "power_connectors": "8-pin + 8-pin",
    "launch_price_usd": 649,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": false,
    "fsr_support": true,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2020-11",
    "notes": "First RDNA 2 GPU with hardware ray tracing, Infinity Cache, and FSR support. Powers PlayStation 5 and Xbox Series X."
  },
  {
    "name": "NVIDIA GeForce RTX 3080 Ti",
    "year": 2021,
    "manufacturer": "NVIDIA",
    "series": "RTX 30",
    "architecture": "Ampere",
    "process_nm": 8,
    "transistors_millions": 28300,
    "die_size_mm2": 628,
    "cuda_cores": 10240,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 320,
    "rt_cores": 80,
    "base_clock_mhz": 1365,
    "boost_clock_mhz": 1665,
    "vram_mb": 12288,
    "memory_type": "GDDR6X",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 912,
    "memory_clock_mhz": 19000,
    "tflops_fp32": 34.1,
    "tflops_fp16": 273,
    "tflops_int8": 273,
    "ray_tracing_tflops": 67,
    "tdp_watts": 350,
    "power_connectors": "2x 8-pin",
    "launch_price_usd": 1199,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2021-06",
    "notes": "Nearly full GA102 die with 12GB VRAM. Popular for AI development but limited by memory capacity compared to 3090. Good for medium-sized model training and inference."
  },
  {
    "name": "NVIDIA GeForce RTX 3090 Ti",
    "year": 2022,
    "manufacturer": "NVIDIA",
    "series": "RTX 30",
    "architecture": "Ampere",
    "process_nm": 8,
    "transistors_millions": 28300,
    "die_size_mm2": 628,
    "cuda_cores": 10752,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 336,
    "rt_cores": 84,
    "base_clock_mhz": 1560,
    "boost_clock_mhz": 1860,
    "vram_mb": 24576,
    "memory_type": "GDDR6X",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 1008,
    "memory_clock_mhz": 21000,
    "tflops_fp32": 40,
    "tflops_fp16": 320,
    "tflops_int8": 320,
    "ray_tracing_tflops": 78,
    "tdp_watts": 450,
    "power_connectors": "1x 16-pin",
    "launch_price_usd": 1999,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": false,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2022-01",
    "notes": "Enhanced RTX 3090 with full GA102 die and faster memory. First consumer GPU to achieve 1TB/s memory bandwidth. Used for AI development and inference workloads."
  },
  {
    "name": "NVIDIA H100 SXM5 80GB",
    "year": 2022,
    "manufacturer": "NVIDIA",
    "series": "H100",
    "architecture": "Hopper",
    "process_nm": 4,
    "transistors_millions": 80000,
    "die_size_mm2": 814,
    "cuda_cores": 16896,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 528,
    "rt_cores": null,
    "base_clock_mhz": 1095,
    "boost_clock_mhz": 1830,
    "vram_mb": 81920,
    "memory_type": "HBM3",
    "memory_bus_width": 5120,
    "memory_bandwidth_gbps": 3350,
    "memory_clock_mhz": 2619,
    "tflops_fp32": 60,
    "tflops_fp16": 1979,
    "tflops_int8": 3958,
    "ray_tracing_tflops": null,
    "tdp_watts": 700,
    "power_connectors": "SXM5",
    "launch_price_usd": 30000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2022-09",
    "notes": "Flagship data center GPU with Transformer Engine and FP8 support. Delivers up to 9x faster AI training and 30x faster inference vs A100 for LLMs. Features NVLink 4.0 with 900GB/s bandwidth."
  },
  {
    "name": "NVIDIA GeForce RTX 4090",
    "year": 2022,
    "manufacturer": "NVIDIA",
    "series": "RTX 40",
    "architecture": "Ada Lovelace",
    "process_nm": 5,
    "transistors_millions": 76300,
    "die_size_mm2": 609,
    "cuda_cores": 16384,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 512,
    "rt_cores": 128,
    "base_clock_mhz": 2230,
    "boost_clock_mhz": 2520,
    "vram_mb": 24576,
    "memory_type": "GDDR6X",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 1008,
    "memory_clock_mhz": 21000,
    "tflops_fp32": 82.58,
    "tflops_fp16": 660,
    "tflops_int8": 660,
    "ray_tracing_tflops": 191,
    "tdp_watts": 450,
    "power_connectors": "1x 16-pin (12VHPWR)",
    "launch_price_usd": 1599,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2022-10",
    "notes": "Consumer flagship with Ada Lovelace architecture. Features 4th-gen Tensor Cores with FP8 support and adapted Transformer Engine. Highly popular for local LLM inference and fine-tuning. DLSS 3.0 with frame generation."
  },
  {
    "name": "AMD Radeon RX 7900 XTX",
    "year": 2022,
    "manufacturer": "AMD",
    "series": "RX 7000",
    "architecture": "RDNA 3",
    "process_nm": 5,
    "transistors_millions": 58000,
    "die_size_mm2": 300,
    "cuda_cores": null,
    "stream_processors": 6144,
    "execution_units": 96,
    "tensor_cores": null,
    "rt_cores": 96,
    "base_clock_mhz": 1900,
    "boost_clock_mhz": 2500,
    "vram_mb": 24576,
    "memory_type": "GDDR6",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 960,
    "memory_clock_mhz": 20000,
    "tflops_fp32": 61,
    "tflops_fp16": 122,
    "tflops_int8": 244,
    "ray_tracing_tflops": 61,
    "tdp_watts": 355,
    "power_connectors": "2x 8-pin",
    "launch_price_usd": 999,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": false,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2022-12",
    "notes": "AMD's consumer flagship with 24GB VRAM. Chiplet-based RDNA 3 architecture with separate GCD and MCD dies. Suitable for AI development with ROCm support, though less optimized than NVIDIA for ML workloads. FSR 3.0 and DisplayPort 2.1 support."
  },
  {
    "name": "Intel Arc A770 16GB",
    "year": 2022,
    "manufacturer": "Intel",
    "series": "Arc A7",
    "architecture": "Xe-HPG",
    "process_nm": 6,
    "transistors_millions": 21700,
    "die_size_mm2": 406,
    "cuda_cores": null,
    "stream_processors": null,
    "execution_units": 512,
    "tensor_cores": 512,
    "rt_cores": 32,
    "base_clock_mhz": 2100,
    "boost_clock_mhz": 2400,
    "vram_mb": 16384,
    "memory_type": "GDDR6",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 560,
    "memory_clock_mhz": 17500,
    "tflops_fp32": 19.66,
    "tflops_fp16": 157.3,
    "tflops_int8": 314.6,
    "ray_tracing_tflops": 19.66,
    "tdp_watts": 225,
    "power_connectors": "2x 8-pin",
    "launch_price_usd": 349,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": false,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2022-10",
    "notes": "Intel's first discrete high-performance GPU with XMX engines for AI acceleration. Supports DP4a and XMX for INT8 operations. Growing support for AI frameworks through Intel Extension for PyTorch. XeSS AI upscaling technology."
  },
  {
    "name": "NVIDIA GeForce RTX 4080",
    "year": 2023,
    "manufacturer": "NVIDIA",
    "series": "RTX 40",
    "architecture": "Ada Lovelace (AD103)",
    "process_nm": 5,
    "transistors_millions": 45900,
    "die_size_mm2": 379,
    "cuda_cores": 9728,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 304,
    "rt_cores": 76,
    "base_clock_mhz": 2205,
    "boost_clock_mhz": 2505,
    "vram_mb": 16384,
    "memory_type": "GDDR6X",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 716.8,
    "memory_clock_mhz": 1400,
    "tflops_fp32": 48.74,
    "tflops_fp16": 97.5,
    "tflops_int8": 390,
    "ray_tracing_tflops": 113.0,
    "tdp_watts": 320,
    "power_connectors": "16-pin (12VHPWR)",
    "launch_price_usd": 1199,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2023-11",
    "notes": "Ada Lovelace architecture with DLSS 3.0 and excellent power efficiency. Good for 4K gaming and medium AI workloads."
  },
  {
    "name": "NVIDIA H100 PCIe 80GB",
    "year": 2023,
    "manufacturer": "NVIDIA",
    "series": "H100",
    "architecture": "Hopper",
    "process_nm": 4,
    "transistors_millions": 80000,
    "die_size_mm2": 814,
    "cuda_cores": 14592,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 456,
    "rt_cores": null,
    "base_clock_mhz": 1095,
    "boost_clock_mhz": 1755,
    "vram_mb": 81920,
    "memory_type": "HBM3",
    "memory_bus_width": 5120,
    "memory_bandwidth_gbps": 2000,
    "memory_clock_mhz": 1593,
    "tflops_fp32": 51.2,
    "tflops_fp16": 1513,
    "tflops_int8": 3026,
    "ray_tracing_tflops": null,
    "tdp_watts": 350,
    "power_connectors": "PCIe 8-pin",
    "launch_price_usd": 25000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2023-03",
    "notes": "PCIe variant of H100 with reduced core count and power. More accessible for standard servers while maintaining strong AI performance with FP8 and Transformer Engine."
  },
  {
    "name": "NVIDIA GeForce RTX 4070",
    "year": 2023,
    "manufacturer": "NVIDIA",
    "series": "RTX 40",
    "architecture": "Ada Lovelace",
    "process_nm": 5,
    "transistors_millions": 35800,
    "die_size_mm2": 295,
    "cuda_cores": 5888,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 184,
    "rt_cores": 46,
    "base_clock_mhz": 1920,
    "boost_clock_mhz": 2475,
    "vram_mb": 12288,
    "memory_type": "GDDR6X",
    "memory_bus_width": 192,
    "memory_bandwidth_gbps": 504,
    "memory_clock_mhz": 21000,
    "tflops_fp32": 29.15,
    "tflops_fp16": 233,
    "tflops_int8": 233,
    "ray_tracing_tflops": 67,
    "tdp_watts": 200,
    "power_connectors": "1x 16-pin (12VHPWR)",
    "launch_price_usd": 599,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2023-04",
    "notes": "Mid-range Ada Lovelace GPU with 12GB VRAM. Efficient for smaller AI models and inference tasks. Good price-to-performance ratio for developers on budget."
  },
  {
    "name": "AMD Radeon RX 7900 XT",
    "year": 2023,
    "manufacturer": "AMD",
    "series": "RX 7000",
    "architecture": "RDNA 3",
    "process_nm": 5,
    "transistors_millions": 58000,
    "die_size_mm2": 300,
    "cuda_cores": null,
    "stream_processors": 5376,
    "execution_units": 84,
    "tensor_cores": null,
    "rt_cores": 84,
    "base_clock_mhz": 1500,
    "boost_clock_mhz": 2400,
    "vram_mb": 20480,
    "memory_type": "GDDR6",
    "memory_bus_width": 320,
    "memory_bandwidth_gbps": 800,
    "memory_clock_mhz": 20000,
    "tflops_fp32": 51.48,
    "tflops_fp16": 103,
    "tflops_int8": 206,
    "ray_tracing_tflops": 51.48,
    "tdp_watts": 300,
    "power_connectors": "2x 8-pin",
    "launch_price_usd": 899,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": false,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2022-12",
    "notes": "Cut-down RDNA 3 GPU with 20GB VRAM. Good memory capacity for AI workloads with ROCm support. Chiplet architecture with separate GCD and MCD dies."
  },
  {
    "name": "Radeon RX 7800 XT",
    "year": 2023,
    "manufacturer": "AMD",
    "series": "Radeon RX 7000",
    "architecture": "RDNA 3.0 (Navi 32)",
    "process_nm": 5,
    "transistors_millions": 28100,
    "die_size_mm2": 200,
    "cuda_cores": null,
    "stream_processors": 3840,
    "execution_units": null,
    "tensor_cores": null,
    "rt_cores": 60,
    "base_clock_mhz": 1800,
    "boost_clock_mhz": 2430,
    "vram_mb": 16384,
    "memory_type": "GDDR6",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 624,
    "memory_clock_mhz": 2438,
    "tflops_fp32": 37.32,
    "tflops_fp16": 74.6,
    "tflops_int8": 0.0,
    "ray_tracing_tflops": 74.0,
    "tdp_watts": 263,
    "power_connectors": "8-pin + 8-pin",
    "launch_price_usd": 499,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": false,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2023-09",
    "notes": "Mid-range RDNA 3 GPU with excellent 1440p performance and 16GB VRAM."
  },
  {
    "name": "AMD Instinct MI300X",
    "year": 2023,
    "manufacturer": "AMD",
    "series": "MI300",
    "architecture": "CDNA 3",
    "process_nm": 5,
    "transistors_millions": 153000,
    "die_size_mm2": 1017,
    "cuda_cores": null,
    "stream_processors": 24576,
    "execution_units": 304,
    "tensor_cores": 912,
    "rt_cores": null,
    "base_clock_mhz": 1700,
    "boost_clock_mhz": 2100,
    "vram_mb": 196608,
    "memory_type": "HBM3",
    "memory_bus_width": 8192,
    "memory_bandwidth_gbps": 5300,
    "memory_clock_mhz": 5200,
    "tflops_fp32": 163.4,
    "tflops_fp16": 1307,
    "tflops_int8": 2615,
    "ray_tracing_tflops": null,
    "tdp_watts": 750,
    "power_connectors": "OAM",
    "launch_price_usd": 30000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2023-12",
    "notes": "AMD's flagship AI accelerator with industry-leading 192GB HBM3 memory and 5.3TB/s bandwidth. Designed for large language model training and inference. Supports FP8 precision and sparsity acceleration. 153 billion transistors in chiplet design."
  },
  {
    "name": "NVIDIA H200 SXM 141GB",
    "year": 2023,
    "manufacturer": "NVIDIA",
    "series": "H200",
    "architecture": "Hopper",
    "process_nm": 4,
    "transistors_millions": 80000,
    "die_size_mm2": 814,
    "cuda_cores": 16896,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 528,
    "rt_cores": null,
    "base_clock_mhz": 1095,
    "boost_clock_mhz": 1830,
    "vram_mb": 144384,
    "memory_type": "HBM3e",
    "memory_bus_width": 5120,
    "memory_bandwidth_gbps": 4800,
    "memory_clock_mhz": 3750,
    "tflops_fp32": 60,
    "tflops_fp16": 1979,
    "tflops_int8": 3958,
    "ray_tracing_tflops": null,
    "tdp_watts": 700,
    "power_connectors": "SXM5",
    "launch_price_usd": 40000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2023-11",
    "notes": "Enhanced H100 with HBM3e memory providing 141GB capacity and 4.8TB/s bandwidth. Designed for the largest LLMs and generative AI workloads. 1.8x memory capacity vs H100."
  },
  {
    "name": "NVIDIA GeForce RTX 4090D",
    "year": 2023,
    "manufacturer": "NVIDIA",
    "series": "RTX 40",
    "architecture": "Ada Lovelace",
    "process_nm": 5,
    "transistors_millions": 76300,
    "die_size_mm2": 609,
    "cuda_cores": 14592,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 456,
    "rt_cores": 114,
    "base_clock_mhz": 2230,
    "boost_clock_mhz": 2520,
    "vram_mb": 24576,
    "memory_type": "GDDR6X",
    "memory_bus_width": 384,
    "memory_bandwidth_gbps": 1008,
    "memory_clock_mhz": 21000,
    "tflops_fp32": 73.54,
    "tflops_fp16": 588,
    "tflops_int8": 588,
    "ray_tracing_tflops": 170,
    "tdp_watts": 425,
    "power_connectors": "1x 16-pin (12VHPWR)",
    "launch_price_usd": 1599,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2023-12",
    "notes": "Export-compliant variant for Chinese market with reduced CUDA and Tensor core count. Maintains 24GB VRAM but with lower compute performance than standard 4090."
  },
  {
    "name": "NVIDIA GeForce RTX 4080 SUPER",
    "year": 2024,
    "manufacturer": "NVIDIA",
    "series": "RTX 40",
    "architecture": "Ada Lovelace",
    "process_nm": 5,
    "transistors_millions": 76300,
    "die_size_mm2": 379,
    "cuda_cores": 10240,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 320,
    "rt_cores": 80,
    "base_clock_mhz": 2295,
    "boost_clock_mhz": 2550,
    "vram_mb": 16384,
    "memory_type": "GDDR6X",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 736,
    "memory_clock_mhz": 23000,
    "tflops_fp32": 52.2,
    "tflops_fp16": 417,
    "tflops_int8": 417,
    "ray_tracing_tflops": 121,
    "tdp_watts": 320,
    "power_connectors": "1x 16-pin (12VHPWR)",
    "launch_price_usd": 999,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2024-01",
    "notes": "Refreshed RTX 4080 with increased core count and faster memory. Good balance of performance and VRAM for AI development and medium-sized model inference."
  },
  {
    "name": "NVIDIA GeForce RTX 4070 Ti SUPER",
    "year": 2024,
    "manufacturer": "NVIDIA",
    "series": "RTX 40",
    "architecture": "Ada Lovelace",
    "process_nm": 5,
    "transistors_millions": 35800,
    "die_size_mm2": 379,
    "cuda_cores": 8448,
    "stream_processors": null,
    "execution_units": null,
    "tensor_cores": 264,
    "rt_cores": 66,
    "base_clock_mhz": 2340,
    "boost_clock_mhz": 2610,
    "vram_mb": 16384,
    "memory_type": "GDDR6X",
    "memory_bus_width": 256,
    "memory_bandwidth_gbps": 672,
    "memory_clock_mhz": 21000,
    "tflops_fp32": 44.1,
    "tflops_fp16": 353,
    "tflops_int8": 353,
    "ray_tracing_tflops": 100,
    "tdp_watts": 285,
    "power_connectors": "1x 16-pin (12VHPWR)",
    "launch_price_usd": 799,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": true,
    "dlss_support": true,
    "fsr_support": true,
    "xess_support": true,
    "max_displays": 4,
    "max_resolution": "7680x4320",
    "release_date": "2024-01",
    "notes": "Mid-range GPU with 16GB VRAM suitable for smaller LLM inference and fine-tuning. Improved performance over original 4070 Ti with more CUDA cores and better value proposition."
  },
  {
    "name": "AMD Instinct MI325X",
    "year": 2024,
    "manufacturer": "AMD",
    "series": "MI300",
    "architecture": "CDNA 3",
    "process_nm": 5,
    "transistors_millions": 153000,
    "die_size_mm2": 1017,
    "cuda_cores": null,
    "stream_processors": 24576,
    "execution_units": 304,
    "tensor_cores": 912,
    "rt_cores": null,
    "base_clock_mhz": 1700,
    "boost_clock_mhz": 2100,
    "vram_mb": 262144,
    "memory_type": "HBM3e",
    "memory_bus_width": 8192,
    "memory_bandwidth_gbps": 6000,
    "memory_clock_mhz": 5860,
    "tflops_fp32": 163.4,
    "tflops_fp16": 1307,
    "tflops_int8": 2615,
    "ray_tracing_tflops": null,
    "tdp_watts": 750,
    "power_connectors": "OAM",
    "launch_price_usd": 35000,
    "directx_version": "12 Ultimate",
    "opengl_version": "4.6",
    "vulkan_support": true,
    "ray_tracing_support": false,
    "dlss_support": false,
    "fsr_support": false,
    "xess_support": false,
    "max_displays": 0,
    "max_resolution": "N/A",
    "release_date": "2024-09",
    "notes": "Enhanced MI300X with 256GB HBM3e memory and 6TB/s bandwidth. Industry-leading memory capacity for the largest AI models. Improved power efficiency and support for matrix sparsity optimizes AI training and inference."
  }
]
