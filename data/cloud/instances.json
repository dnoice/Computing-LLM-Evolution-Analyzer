[
  {
    "provider": "AWS",
    "instance_type": "p3.2xlarge",
    "instance_family": "P3",
    "year": 2017,
    "region": "us-east-1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA V100",
    "gpu_memory_gb": 16,
    "vcpus": 8,
    "ram_gb": 61,
    "storage_gb": 0,
    "storage_type": "EBS-only",
    "network_bandwidth_gbps": 10,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 32,
    "tflops_fp32": 15.7,
    "tflops_fp16": 125,
    "tflops_int8": 0,
    "tensor_cores": true,
    "price_ondemand_hourly": 3.06,
    "price_spot_hourly": 0.918,
    "price_1yr_reserved_hourly": 1.87,
    "price_3yr_reserved_hourly": 1.12,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.10,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "First V100-based instance from AWS. Good for deep learning training. EBS-only storage."
  },
  {
    "provider": "AWS",
    "instance_type": "p3.8xlarge",
    "instance_family": "P3",
    "year": 2017,
    "region": "us-east-1",
    "gpu_count": 4,
    "gpu_model": "NVIDIA V100",
    "gpu_memory_gb": 64,
    "vcpus": 32,
    "ram_gb": 244,
    "storage_gb": 0,
    "storage_type": "EBS-only",
    "network_bandwidth_gbps": 10,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 300,
    "tflops_fp32": 62.8,
    "tflops_fp16": 500,
    "tflops_int8": 0,
    "tensor_cores": true,
    "price_ondemand_hourly": 12.24,
    "price_spot_hourly": 3.672,
    "price_1yr_reserved_hourly": 7.48,
    "price_3yr_reserved_hourly": 4.48,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.10,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "4x V100 with NVLink for faster GPU-to-GPU communication. Well-balanced for multi-GPU training."
  },
  {
    "provider": "AWS",
    "instance_type": "p3.16xlarge",
    "instance_family": "P3",
    "year": 2017,
    "region": "us-east-1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA V100",
    "gpu_memory_gb": 128,
    "vcpus": 64,
    "ram_gb": 488,
    "storage_gb": 0,
    "storage_type": "EBS-only",
    "network_bandwidth_gbps": 25,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 300,
    "tflops_fp32": 125.6,
    "tflops_fp16": 1000,
    "tflops_int8": 0,
    "tensor_cores": true,
    "price_ondemand_hourly": 24.48,
    "price_spot_hourly": 7.344,
    "price_1yr_reserved_hourly": 14.96,
    "price_3yr_reserved_hourly": 8.96,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.10,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "8x V100 configuration. Maximum P3 instance size. 25 Gbps network for multi-node training."
  },
  {
    "provider": "AWS",
    "instance_type": "p4d.24xlarge",
    "instance_family": "P4d",
    "year": 2020,
    "region": "us-east-1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA A100 (40GB)",
    "gpu_memory_gb": 320,
    "vcpus": 96,
    "ram_gb": 1152,
    "storage_gb": 8000,
    "storage_type": "NVMe SSD",
    "network_bandwidth_gbps": 400,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 156,
    "tflops_fp16": 312,
    "tflops_int8": 624,
    "tensor_cores": true,
    "price_ondemand_hourly": 32.77,
    "price_spot_hourly": 9.83,
    "price_1yr_reserved_hourly": 20.01,
    "price_3yr_reserved_hourly": 11.99,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "8x A100 40GB with 400 Gbps EFA. 8 TB local NVMe storage. Part of EC2 UltraClusters. Excellent for large-scale distributed training."
  },
  {
    "provider": "AWS",
    "instance_type": "p5.48xlarge",
    "instance_family": "P5",
    "year": 2023,
    "region": "us-east-1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA H100 (80GB)",
    "gpu_memory_gb": 640,
    "vcpus": 192,
    "ram_gb": 2048,
    "storage_gb": 30400,
    "storage_type": "NVMe SSD",
    "network_bandwidth_gbps": 3200,
    "gpu_interconnect": "NVSwitch",
    "gpu_interconnect_bandwidth_gbps": 900,
    "tflops_fp32": 268,
    "tflops_fp16": 1979,
    "tflops_int8": 3958,
    "tensor_cores": true,
    "price_ondemand_hourly": 98.32,
    "price_spot_hourly": 29.50,
    "price_1yr_reserved_hourly": 60.00,
    "price_3yr_reserved_hourly": 36.00,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "Latest H100-based instance. 8x H100 80GB with 3200 Gbps EFA. 30 TB local NVMe. Deployed in EC2 UltraClusters with up to 20K GPUs. 4x faster than P4d for LLM training."
  },
  {
    "provider": "AWS",
    "instance_type": "g4dn.xlarge",
    "instance_family": "G4dn",
    "year": 2019,
    "region": "us-east-1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA T4",
    "gpu_memory_gb": 16,
    "vcpus": 4,
    "ram_gb": 16,
    "storage_gb": 125,
    "storage_type": "NVMe SSD",
    "network_bandwidth_gbps": 25,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 32,
    "tflops_fp32": 8.1,
    "tflops_fp16": 65,
    "tflops_int8": 130,
    "tensor_cores": true,
    "price_ondemand_hourly": 0.526,
    "price_spot_hourly": 0.158,
    "price_1yr_reserved_hourly": 0.32,
    "price_3yr_reserved_hourly": 0.19,
    "ml_optimized": false,
    "inference_optimized": true,
    "training_optimized": false,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "Cost-effective T4 instance for inference. Good INT8 performance. 125 GB NVMe storage included."
  },
  {
    "provider": "AWS",
    "instance_type": "g5.xlarge",
    "instance_family": "G5",
    "year": 2021,
    "region": "us-east-1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA A10G",
    "gpu_memory_gb": 24,
    "vcpus": 4,
    "ram_gb": 16,
    "storage_gb": 250,
    "storage_type": "NVMe SSD",
    "network_bandwidth_gbps": 10,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 32,
    "tflops_fp32": 31.2,
    "tflops_fp16": 125,
    "tflops_int8": 250,
    "tensor_cores": true,
    "price_ondemand_hourly": 1.006,
    "price_spot_hourly": 0.302,
    "price_1yr_reserved_hourly": 0.61,
    "price_3yr_reserved_hourly": 0.37,
    "ml_optimized": true,
    "inference_optimized": true,
    "training_optimized": false,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "A10G-based instance. Good balance for inference and light training. 24GB memory. 250 GB NVMe."
  },
  {
    "provider": "AWS",
    "instance_type": "g5.48xlarge",
    "instance_family": "G5",
    "year": 2021,
    "region": "us-east-1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA A10G",
    "gpu_memory_gb": 192,
    "vcpus": 192,
    "ram_gb": 768,
    "storage_gb": 7600,
    "storage_type": "NVMe SSD",
    "network_bandwidth_gbps": 100,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 249.6,
    "tflops_fp16": 1000,
    "tflops_int8": 2000,
    "tensor_cores": true,
    "price_ondemand_hourly": 16.288,
    "price_spot_hourly": 4.886,
    "price_1yr_reserved_hourly": 9.95,
    "price_3yr_reserved_hourly": 5.97,
    "ml_optimized": true,
    "inference_optimized": true,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0,
    "egress_cost_per_gb": 0.09,
    "availability": "GA",
    "notes": "8x A10G with NVLink. Cost-effective for medium-scale training and inference. 7.6 TB local storage."
  },
  {
    "provider": "GCP",
    "instance_type": "a2-highgpu-1g",
    "instance_family": "A2",
    "year": 2021,
    "region": "us-central1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA A100 (40GB)",
    "gpu_memory_gb": 40,
    "vcpus": 12,
    "ram_gb": 85,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 24,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 64,
    "tflops_fp32": 19.5,
    "tflops_fp16": 156,
    "tflops_int8": 312,
    "tensor_cores": true,
    "price_ondemand_hourly": 3.673,
    "price_spot_hourly": 1.102,
    "price_1yr_reserved_hourly": 2.57,
    "price_3yr_reserved_hourly": 1.84,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "Single A100 40GB instance. Good for development and small-scale training. Uses Persistent Disk for storage."
  },
  {
    "provider": "GCP",
    "instance_type": "a2-highgpu-8g",
    "instance_family": "A2",
    "year": 2021,
    "region": "us-central1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA A100 (40GB)",
    "gpu_memory_gb": 320,
    "vcpus": 96,
    "ram_gb": 680,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 100,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 156,
    "tflops_fp16": 1248,
    "tflops_int8": 2496,
    "tensor_cores": true,
    "price_ondemand_hourly": 29.39,
    "price_spot_hourly": 8.82,
    "price_1yr_reserved_hourly": 20.57,
    "price_3yr_reserved_hourly": 14.70,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "8x A100 40GB with NVLink. Full A2 instance. 600 GB/s GPU interconnect bandwidth."
  },
  {
    "provider": "GCP",
    "instance_type": "a2-ultragpu-1g",
    "instance_family": "A2 Ultra",
    "year": 2022,
    "region": "us-central1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA A100 (80GB)",
    "gpu_memory_gb": 80,
    "vcpus": 12,
    "ram_gb": 170,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 24,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 64,
    "tflops_fp32": 19.5,
    "tflops_fp16": 312,
    "tflops_int8": 624,
    "tensor_cores": true,
    "price_ondemand_hourly": 5.35,
    "price_spot_hourly": 1.61,
    "price_1yr_reserved_hourly": 3.75,
    "price_3yr_reserved_hourly": 2.68,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "Single A100 80GB instance. Double memory of standard A2. HBM2e memory for higher bandwidth."
  },
  {
    "provider": "GCP",
    "instance_type": "a2-ultragpu-8g",
    "instance_family": "A2 Ultra",
    "year": 2022,
    "region": "us-central1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA A100 (80GB)",
    "gpu_memory_gb": 640,
    "vcpus": 96,
    "ram_gb": 1360,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 100,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 156,
    "tflops_fp16": 2496,
    "tflops_int8": 4992,
    "tensor_cores": true,
    "price_ondemand_hourly": 42.80,
    "price_spot_hourly": 12.84,
    "price_1yr_reserved_hourly": 29.96,
    "price_3yr_reserved_hourly": 21.40,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "8x A100 80GB. Full A2 Ultra. 640 GB total GPU memory for large models. NVLink interconnect."
  },
  {
    "provider": "GCP",
    "instance_type": "a3-highgpu-1g",
    "instance_family": "A3",
    "year": 2023,
    "region": "us-central1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA H100 (80GB)",
    "gpu_memory_gb": 80,
    "vcpus": 26,
    "ram_gb": 234,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 100,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 64,
    "tflops_fp32": 51,
    "tflops_fp16": 1979,
    "tflops_int8": 3958,
    "tensor_cores": true,
    "price_ondemand_hourly": 11.07,
    "price_spot_hourly": 3.32,
    "price_1yr_reserved_hourly": 7.75,
    "price_3yr_reserved_hourly": 5.54,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "Single H100 80GB instance. Intel Sapphire Rapids CPU. Good for development with latest GPU."
  },
  {
    "provider": "GCP",
    "instance_type": "a3-highgpu-8g",
    "instance_family": "A3",
    "year": 2023,
    "region": "us-central1",
    "gpu_count": 8,
    "gpu_model": "NVIDIA H100 (80GB)",
    "gpu_memory_gb": 640,
    "vcpus": 208,
    "ram_gb": 1872,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 200,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 900,
    "tflops_fp32": 408,
    "tflops_fp16": 15832,
    "tflops_int8": 31664,
    "tensor_cores": true,
    "price_ondemand_hourly": 88.49,
    "price_spot_hourly": 26.55,
    "price_1yr_reserved_hourly": 61.94,
    "price_3yr_reserved_hourly": 44.25,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "8x H100 80GB. Full A3 instance. 900 GB/s NVLink bandwidth. Competitive with AWS P5 pricing."
  },
  {
    "provider": "GCP",
    "instance_type": "g2-standard-4",
    "instance_family": "G2",
    "year": 2023,
    "region": "us-central1",
    "gpu_count": 1,
    "gpu_model": "NVIDIA L4",
    "gpu_memory_gb": 24,
    "vcpus": 4,
    "ram_gb": 16,
    "storage_gb": 0,
    "storage_type": "Persistent Disk",
    "network_bandwidth_gbps": 32,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 64,
    "tflops_fp32": 30,
    "tflops_fp16": 242,
    "tflops_int8": 485,
    "tensor_cores": true,
    "price_ondemand_hourly": 0.86,
    "price_spot_hourly": 0.26,
    "price_1yr_reserved_hourly": 0.60,
    "price_3yr_reserved_hourly": 0.43,
    "ml_optimized": false,
    "inference_optimized": true,
    "training_optimized": false,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0.04,
    "egress_cost_per_gb": 0.12,
    "availability": "GA",
    "notes": "Cost-effective L4 instance for inference. Ada Lovelace architecture. Good for video and AI inference."
  },
  {
    "provider": "Azure",
    "instance_type": "NC6s_v3",
    "instance_family": "NCv3",
    "year": 2018,
    "region": "eastus",
    "gpu_count": 1,
    "gpu_model": "NVIDIA V100",
    "gpu_memory_gb": 16,
    "vcpus": 6,
    "ram_gb": 112,
    "storage_gb": 736,
    "storage_type": "SSD",
    "network_bandwidth_gbps": 24,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 32,
    "tflops_fp32": 15.7,
    "tflops_fp16": 125,
    "tflops_int8": 0,
    "tensor_cores": true,
    "price_ondemand_hourly": 3.06,
    "price_spot_hourly": 0.52,
    "price_1yr_reserved_hourly": 1.98,
    "price_3yr_reserved_hourly": 1.31,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "Single V100 instance. Good for development and small training jobs. 736 GB local SSD."
  },
  {
    "provider": "Azure",
    "instance_type": "NC24s_v3",
    "instance_family": "NCv3",
    "year": 2018,
    "region": "eastus",
    "gpu_count": 4,
    "gpu_model": "NVIDIA V100",
    "gpu_memory_gb": 64,
    "vcpus": 24,
    "ram_gb": 448,
    "storage_gb": 2948,
    "storage_type": "SSD",
    "network_bandwidth_gbps": 24,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 300,
    "tflops_fp32": 62.8,
    "tflops_fp16": 500,
    "tflops_int8": 0,
    "tensor_cores": true,
    "price_ondemand_hourly": 12.24,
    "price_spot_hourly": 2.08,
    "price_1yr_reserved_hourly": 7.92,
    "price_3yr_reserved_hourly": 5.24,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "4x V100 with NVLink. Full NCv3 instance. Nearly 3 TB local SSD storage."
  },
  {
    "provider": "Azure",
    "instance_type": "NC24ads_A100_v4",
    "instance_family": "NCads_A100_v4",
    "year": 2021,
    "region": "eastus",
    "gpu_count": 1,
    "gpu_model": "NVIDIA A100 (80GB)",
    "gpu_memory_gb": 80,
    "vcpus": 24,
    "ram_gb": 220,
    "storage_gb": 1123,
    "storage_type": "SSD",
    "network_bandwidth_gbps": 40,
    "gpu_interconnect": "PCIe",
    "gpu_interconnect_bandwidth_gbps": 64,
    "tflops_fp32": 19.5,
    "tflops_fp16": 312,
    "tflops_int8": 624,
    "tensor_cores": true,
    "price_ondemand_hourly": 3.67,
    "price_spot_hourly": 0.62,
    "price_1yr_reserved_hourly": 2.37,
    "price_3yr_reserved_hourly": 1.57,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": false,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "Single A100 80GB. AMD EPYC CPU. Good price/performance for development."
  },
  {
    "provider": "Azure",
    "instance_type": "NC96ads_A100_v4",
    "instance_family": "NCads_A100_v4",
    "year": 2021,
    "region": "eastus",
    "gpu_count": 4,
    "gpu_model": "NVIDIA A100 (80GB)",
    "gpu_memory_gb": 320,
    "vcpus": 96,
    "ram_gb": 880,
    "storage_gb": 6492,
    "storage_type": "SSD",
    "network_bandwidth_gbps": 200,
    "gpu_interconnect": "NVLink",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 78,
    "tflops_fp16": 1248,
    "tflops_int8": 2496,
    "tensor_cores": true,
    "price_ondemand_hourly": 14.69,
    "price_spot_hourly": 2.50,
    "price_1yr_reserved_hourly": 9.50,
    "price_3yr_reserved_hourly": 6.29,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "4x A100 80GB with NVLink. Full NCads_A100_v4. AMD EPYC 7V13 CPU. 6.5 TB local storage."
  },
  {
    "provider": "Azure",
    "instance_type": "ND96asr_v4",
    "instance_family": "NDasr_v4",
    "year": 2020,
    "region": "eastus",
    "gpu_count": 8,
    "gpu_model": "NVIDIA A100 (40GB)",
    "gpu_memory_gb": 320,
    "vcpus": 96,
    "ram_gb": 900,
    "storage_gb": 6000,
    "storage_type": "SSD",
    "network_bandwidth_gbps": 400,
    "gpu_interconnect": "NVLink + InfiniBand",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 156,
    "tflops_fp16": 1248,
    "tflops_int8": 2496,
    "tensor_cores": true,
    "price_ondemand_hourly": 27.20,
    "price_spot_hourly": 4.62,
    "price_1yr_reserved_hourly": 17.59,
    "price_3yr_reserved_hourly": 11.64,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "8x A100 40GB. 200 Gbps HDR InfiniBand for multi-node. Optimized for distributed training at scale."
  },
  {
    "provider": "Azure",
    "instance_type": "ND96amsr_A100_v4",
    "instance_family": "NDamsr_A100_v4",
    "year": 2022,
    "region": "eastus",
    "gpu_count": 8,
    "gpu_model": "NVIDIA A100 (80GB)",
    "gpu_memory_gb": 640,
    "vcpus": 96,
    "ram_gb": 1924,
    "storage_gb": 6400,
    "storage_type": "SSD",
    "network_bandwidth_gbps": 400,
    "gpu_interconnect": "NVLink + InfiniBand",
    "gpu_interconnect_bandwidth_gbps": 600,
    "tflops_fp32": 156,
    "tflops_fp16": 2496,
    "tflops_int8": 4992,
    "tensor_cores": true,
    "price_ondemand_hourly": 36.87,
    "price_spot_hourly": 6.27,
    "price_1yr_reserved_hourly": 23.84,
    "price_3yr_reserved_hourly": 15.78,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "8x A100 80GB. 200 Gbps InfiniBand. Nearly 2 TB RAM. Top-tier for large-scale distributed training."
  },
  {
    "provider": "Azure",
    "instance_type": "ND96isr_H100_v5",
    "instance_family": "NDisr_H100_v5",
    "year": 2023,
    "region": "eastus",
    "gpu_count": 8,
    "gpu_model": "NVIDIA H100 (80GB)",
    "gpu_memory_gb": 640,
    "vcpus": 96,
    "ram_gb": 1900,
    "storage_gb": 7500,
    "storage_type": "NVMe SSD",
    "network_bandwidth_gbps": 800,
    "gpu_interconnect": "NVSwitch + InfiniBand",
    "gpu_interconnect_bandwidth_gbps": 900,
    "tflops_fp32": 268,
    "tflops_fp16": 15832,
    "tflops_int8": 31664,
    "tensor_cores": true,
    "price_ondemand_hourly": 95.23,
    "price_spot_hourly": 16.19,
    "price_1yr_reserved_hourly": 61.56,
    "price_3yr_reserved_hourly": 40.76,
    "ml_optimized": true,
    "inference_optimized": false,
    "training_optimized": true,
    "supports_multi_node": true,
    "storage_cost_per_gb_month": 0.05,
    "egress_cost_per_gb": 0.087,
    "availability": "GA",
    "notes": "8x H100 80GB. Latest Azure GPU instance. 400 Gbps InfiniBand. 7.5 TB NVMe. Competitive with AWS P5."
  }
]
